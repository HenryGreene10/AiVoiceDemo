<!doctype html>
<html lang="en">
<head>
  <!-- ===== Page metadata (keep title for SEO; the reader uses <h1>) ===== -->
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Where should archaeologists dig next?</title>
  <meta name="description" content="OpenAI contest winners used machine learning to predict new archaeological sites in the Amazon." />
  <meta name="author" content="National Geographic Staff" />

  <!-- ===== Player styles (serve these from your root) ===== -->
  <link rel="stylesheet" href="/mini-player.css?v=108" />
  <link rel="stylesheet" href="/pro-player.css?v=108" />

  <!-- ===== Page look + icon variables for mini-player (optional) ===== -->
  <style>
    :root{
      /* custom icons for the mini-player (optional) */
      --mp-icon: 20px;
      --icon-play:  url('/icons/my-play.svg');
      --icon-pause: url('/icons/my-pause.svg');
      --icon-back:  url('/icons/my-back.svg');
      --icon-fwd:   url('/icons/my-fwd.svg');
    }
    body{
      font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif;
      margin: 0; padding: 24px; background: #ffffff;
    }
    main{ max-width: 720px; margin: 0 auto; }
  </style>
  <script>
    /* Enables the CSS mask-icon mode in mini-player.css */
    document.documentElement.classList.add('custom-icons');
  </script>
</head>







<script>
  (function(){
    const BASE   = "https://aivoicedemo.onrender.com";   // your backend
    const VOICE  = "21m00Tcm4TlvDq8ikWAM";               // your ElevenLabs voice
    const TENANT = "demo123";                             // optional header
    const SEL    = "#demo-article";                       // article container
  
    async function ensureMini(){
      if (window.AiMini) return;
      await new Promise((resolve, reject)=>{
        const s=document.createElement("script");
        s.src="/mini-player.js?v=108";
        s.onload=resolve; s.onerror=reject;
        document.head.appendChild(s);
      });
    }
  
    function buildText(){
      const h1  = document.querySelector("h1")?.innerText?.trim() || "AI Listen";
      const dek = document.querySelector(".dek,.subtitle,h2")?.innerText?.trim() || "";
      const by  = (document.querySelector(".byline")?.textContent || "")
                    .replace(/^By\s*/i,"").trim();
      let body = "";
      (document.querySelector(SEL) || document.body)
        .querySelectorAll("p,li,blockquote")
        .forEach(n => { const s=(n.innerText||"").replace(/\s+/g," ").trim(); if (s) body += s + " "; });
  
      // de-dup if body starts with the title/byline
      if (body.toLowerCase().startsWith(h1.toLowerCase())) body = body.slice(h1.length).trim();
      body = body.replace(/^\s*By\s+.+?\s{2,}/i,"");
  
      return [h1, dek, by ? `By ${by}` : "", body].filter(Boolean).join("\n\n").slice(0,12000);
    }
  
    async function play(){
      await ensureMini();
  
      const h1  = document.querySelector("h1")?.innerText?.trim() || "AI Listen";
      const sub = (document.querySelector(".dek")?.innerText?.trim())
               || (document.querySelector(".byline")?.textContent?.trim())
               || location.hostname;
  
      // open mini immediately
      window.AiMini.open({ title: h1, subtitle: sub });
  
      // request TTS
      const text = buildText();
      const r = await fetch(BASE + "/api/tts", {
        method:"POST",
        headers:{ "content-type":"application/json", "x-tenant-key":TENANT },
        body: JSON.stringify({ text, voice_id: VOICE, preset: "news" })
      });
      const raw = await r.text();
      if (!r.ok) throw new Error(`TTS ${r.status}: ${raw}`);
      const j = JSON.parse(raw);
      let url = j.audioUrl || j.audio_url || j.url;
      if (url && !/^https?:\/\//i.test(url)) url = BASE + url;
  
      const a = window.AiMini.audio?.() || document.getElementById("ai-listen-audio") || (()=> {
        const el=document.createElement("audio"); el.id="ai-listen-audio"; document.body.appendChild(el); return el;
      })();
      try{ a.pause(); a.removeAttribute("src"); a.currentTime = 0; }catch{}
      a.src = url; a.preload="auto";
      a.addEventListener("canplay", ()=> a.play().catch(()=>{}), {once:true});
      a.load();
    }
  
    // bind to your visible button
    window.addEventListener("click", e=>{
      const btn = e.target.closest("#ai-listen-btn");
      if (!btn) return;
      e.preventDefault();
      play().catch(err=>{
        console.error("[AIL hotfix] play failed", err);
        alert("Playback error (see console).");
      });
    });
  })();
  </script>


  
  



<body>
  <!-- ===== Article content (the reader pulls text from #demo-article) ===== -->
  <main class="article">
    <header class="article-header">
      <!-- H1 is what the mini-player shows as title -->
      <h1>Where should archaeologists dig next? The winners of this OpenAI contest can tell them.</h1>
      
      <!-- Optional subheading/dek (read before body with a short pause) -->
      <p class="dek">Machine learning points to dozens of likely archaeological sites hidden across the Amazon rainforest.</p>

      <!-- Byline (the reader says “By …” once; we strip duplicates from body) -->
      <div class="byline">By National Geographic Staff</div>
      <br>
      <button id="ai-listen-btn" class="listen-btn">Listen</button>
      <!-- The widget (v108+) will insert the Listen pill right under the H1 -->
    </header>

    

    <!-- Paste ONLY readable story text here: paragraphs, lists, blockquotes. -->
    <!-- You can omit images, captions, embeds, and footnotes (the widget strips them anyway). -->
    <article id="demo-article" class="article-body">
      <!-- Replace these sample paragraphs with the NatGeo article text -->
      <p>Buried deep within millions of square miles of dense Amazon rainforest may lie tens of thousands of hidden archeological sites, where stone tools and rock paintings 
        are testaments to civilizations that existed as far back as 13,000 years ago.</p>
      <p>But the thick forest sprawled across nine countries and home to hundreds of Indigenous groups today, is too vast and often difficult for archeologists to physically 
        survey for hidden sites. Increasingly, researchers are looking to newer technologies like Artificial Intelligence and machine learning for help. </p>
      <p>That's why two archaeologists recently collaborated with OpenAI, the company behind ChatGPT, to judge a public competition encouraging tech enthusiasts
         to explore large troves of satellite images and remote sensor data for signs of undiscovered archeological sites.</p>
      <p>The winning three-person team of the "OpenAI to Z Challenge," announced Thursday, found 67 distinct patches across the Amazon, each measuring about a 
        square mile, that they think could contain historically valuable ancient sites and provide potential starting points for field exploration. 
        The judges included Egyptologist Sarah Parcak and Mesoamerican archaeologist Chris Fisher.</p>
      <p>The winning team, which calls itself “Black Bean,” trained deep learning models on several publicly available datasets, including remote sensing LiDAR data
         and satellite images from Google Earth Engine and NASA's digital elevation models, among others. The team says they then used OpenAI's GPT-4o model to learn
          the pattern of known archeological sites in the Amazon rainforest and compare them to unexplored swaths of the Amazon, mainly in Brazil.
           It then highlighted dozens of coordinates for future exploration.</p>
      <p>Many of the areas they identified appeared to be clustered along bodies of water.
        “Our results actually make sense on a common-sense level,” says Yao Zhao, a member of the winning team who is 
        currently a software engineer at Meta, and was on a career break during the competition to learn more about AI applications. Ancient civilizations, after all, tended to flourish near accessible water sources. 
        Being able to quickly churn through millions of square miles of geographic data within a few weeks could 
        make it easier for archeologists to find patterns without relying on groundwork first, he adds. The first-place winners received a $250,000 cash prize and credits to use premium OpenAI products.</p>
      
      <h2>Adding AI to the archaeologist's toolkit</h2>
      <p>Machine learning isn't a completely new tool to explorers of the ancient world. Parcak, an archeologist at the University of Alabama at Birmingham, has used satellite images, thermal imaging and LiDAR, 
        which employs planes or drones to emit pulses from sensors and observe their return, for a few decades in her exploration of Egypt, Tunisia and other countries.</p>
      <p>Those imaging tools and techniques, combined with machine learning trained to find patterns in data, have helped her uncover thousands of previously unknown settlements and tombs within 
        known archeological sites. But newer AI models could build on those uses by looking beyond established archeological targets, turning up entirely new areas for archeologists to investigate, she says. </p>
      <p>Many sites are disappearing across the world as sea levels rise, vegetation spreads or recedes, and as humans build and migrate, abandoning or destroying valuable historical records.</p>
<!-- ...more <p>…</p> blocks as needed ... -->
    </article>
  </main>

  <!-- ===== Scripts =====
       You do NOT need any button-mover or SSML scripts.
       The widget loads the mini-player and places the Listen pill for you.
       Attach any ElevenLabs pronunciation dictionary to the same voice you use below. -->
  <script
    src="/tts-widget.v108.js"
    data-base="https://aivoicedemo.onrender.com"
    data-voice="21m00Tcm4TlvDq8ikWAM"           
    data-tenant="demo123"                       
    data-selector="#demo-article">               
  </script>

  <!-- (Optional) If you also ship a pronunciation dictionary file in ElevenLabs,
       you don't need to change this HTML: just attach that dictionary to the voice
       used in data-voice inside the ElevenLabs dashboard. -->
</body>
</html>
