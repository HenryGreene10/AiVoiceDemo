<!doctype html>
<html lang="en">
<head>
  <!-- ===== Page metadata (keep title for SEO; the reader uses <h1>) ===== -->
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Where should archaeologists dig next?</title>
  <meta name="description" content="OpenAI contest winners used machine learning to predict new archaeological sites in the Amazon." />
  <meta name="author" content="National Geographic Staff" />

  <!-- ===== Player styles (serve these from your root) ===== -->
  <link rel="stylesheet" href="/mini-player.css?v=108" />
  <link rel="stylesheet" href="/pro-player.css?v=108" />

  <!-- ===== Page look + icon variables for mini-player (optional) ===== -->
  <style>
    :root{
      /* custom icons for the mini-player (optional) */
      --mp-icon: 20px;
      --icon-play:  url('/icons/my-play.svg');
      --icon-pause: url('/icons/my-pause.svg');
      --icon-back:  url('/icons/my-back.svg');
      --icon-fwd:   url('/icons/my-fwd.svg');
    }
    body{
      font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif;
      margin: 0; padding: 24px; background: #ffffff;
    }
    main{ max-width: 720px; margin: 0 auto; }

    /* timebar numbers in black */
    #mp-elapsed, #mp-total { color:#000; }
  </style>

  <script>
    /* Enables the CSS mask-icon mode in mini-player.css */
    document.documentElement.classList.add('custom-icons');
  </script>

  <!-- ===== DEMO FLAGS (cost-safe). Toggle live with ?live=1 if you want. ===== -->
  <script>
    // Default: demo mode (no backend calls)
    window.AIL_DISABLE_TTS = true;
    window.AIL_AUDIO_URL   = "/audio/article-demo3.mp3"; // make sure this exists

    // Optional private live toggle: add ?live=1 to the URL to enable backend
    try {
      const qp = new URL(location.href).searchParams;
      if (qp.get("live") === "1") window.AIL_DISABLE_TTS = false;
    } catch {}
  </script>
</head>

<body>
  <!-- ===== Article content (the reader pulls text from #demo-article) ===== -->
  <main class="article">
    <header class="article-header">
      <!-- H1 is what the mini-player shows as title (we truncate to 5 words in the mini) -->
      <h1>Where should archaeologists dig next? The winners of this OpenAI contest can tell them.</h1>

      <!-- Optional subheading/dek (read before body with a short pause) -->
      <p class="dek">Machine learning points to dozens of likely archaeological sites hidden across the Amazon rainforest.</p>

      <!-- Byline (the reader says “By …” once; we strip duplicates from body) -->
      <div class="byline">By National Geographic Staff</div>
      <br>
      <button id="ai-listen-btn" class="listen-btn">Listen</button>
    </header>

    <!-- Paste ONLY readable story text here: paragraphs, lists, blockquotes. -->
    <article id="demo-article" class="article-body">
      <p>Buried deep within millions of square miles of dense Amazon rainforest may lie tens of thousands of hidden archeological sites, where stone tools and rock paintings are testaments to civilizations that existed as far back as 13,000 years ago.</p>
      <p>But the thick forest sprawled across nine countries and home to hundreds of Indigenous groups today, is too vast and often difficult for archeologists to physically survey for hidden sites. Increasingly, researchers are looking to newer technologies like Artificial Intelligence and machine learning for help. </p>
      <p>That's why two archaeologists recently collaborated with OpenAI, the company behind ChatGPT, to judge a public competition encouraging tech enthusiasts to explore large troves of satellite images and remote sensor data for signs of undiscovered archeological sites.</p>
      <p>The winning three-person team of the "OpenAI to Z Challenge," announced Thursday, found 67 distinct patches across the Amazon, each measuring about a square mile, that they think could contain historically valuable ancient sites and provide potential starting points for field exploration. The judges included Egyptologist Sarah Parcak and Mesoamerican archaeologist Chris Fisher.</p>
      <p>The winning team, which calls itself “Black Bean,” trained deep learning models on several publicly available datasets, including remote sensing LiDAR data and satellite images from Google Earth Engine and NASA's digital elevation models, among others. The team says they then used OpenAI's GPT-4o model to learn the pattern of known archeological sites in the Amazon rainforest and compare them to unexplored swaths of the Amazon, mainly in Brazil. It then highlighted dozens of coordinates for future exploration.</p>
      <p>Many of the areas they identified appeared to be clustered along bodies of water. “Our results actually make sense on a common-sense level,” says Yao Zhao, a member of the winning team who is currently a software engineer at Meta, and was on a career break during the competition to learn more about AI applications. Ancient civilizations, after all, tended to flourish near accessible water sources. Being able to quickly churn through millions of square miles of geographic data within a few weeks could make it easier for archeologists to find patterns without relying on groundwork first, he adds. The first-place winners received a $250,000 cash prize and credits to use premium OpenAI products.</p>

      <h2>Adding AI to the archaeologist's toolkit</h2>
      <p>Machine learning isn't a completely new tool to explorers of the ancient world. Parcak, an archeologist at the University of Alabama at Birmingham, has used satellite images, thermal imaging and LiDAR, which employs planes or drones to emit pulses from sensors and observe their return, for a few decades in her exploration of Egypt, Tunisia and other countries.</p>
      <p>Those imaging tools and techniques, combined with machine learning trained to find patterns in data, have helped her uncover thousands of previously unknown settlements and tombs within known archeological sites. But newer AI models could build on those uses by looking beyond established archeological targets, turning up entirely new areas for archeologists to investigate, she says. </p>
      <p>Many sites are disappearing across the world as sea levels rise, vegetation spreads or recedes, and as humans build and migrate, abandoning or destroying valuable historical records.</p>
    </article>

    <!-- Baseline comparison (competitor stand-in): native HTML5 audio -->
    <section style="margin-top:20px;padding-top:8px;border-top:1px solid #eee">
      <h3>Baseline audio (HTML5 controls)</h3>
      <audio controls preload="metadata" style="width:100%">
        <source src="/audio/article-demo.mp3" type="audio/mpeg" />
      </audio>
      <small>For side-by-side UX comparison. This is static and cost-free.</small>
    </section>
  </main>

  <!-- ===== SIMPLE API helper (kept, but short-circuited for demo) ===== -->
  <script>
    const API_BASE = "https://aivoicedemo.onrender.com"; // your backend (only used when live)

    async function playViaApi() {
      const a = document.getElementById("player") || new Audio();
      a.id = "player";

      // DEMO SHORT-CIRCUIT
      if (window.AIL_DISABLE_TTS && window.AIL_AUDIO_URL) {
        a.src = window.AIL_AUDIO_URL;
        await a.play().catch(()=>{});
        return;
      }

      // Live path (only when ?live=1)
      const res = await fetch(`${API_BASE}/api/tts`, {
        method: "POST",
        headers: { "content-type": "application/json" }
      });
      if (!res.ok) throw new Error(await res.text());
      const { audioUrl } = await res.json();
      a.src = audioUrl;
      await a.play().catch(()=>{});
    }
  </script>

  <!-- ===== HOTFIX: mini loader + full-article narration + trunc title + number prosody ===== -->
  <script>
  (function(){
    const BASE   = "https://aivoicedemo.onrender.com"; // backend base (only when live)
    const VOICE  = "21m00Tcm4TlvDq8ikWAM";
    const TENANT = "demo123";
    const SEL    = "#demo-article";

    function firstWords(str, n=5){
      const w=(str||"").trim().split(/\s+/);
      return w.length<=n ? (str||"") : w.slice(0,n).join(" ") + "…";
    }
    function numberToWordsUS(num){
      const ones=["zero","one","two","three","four","five","six","seven","eight","nine"];
      const teens=["ten","eleven","twelve","thirteen","fourteen","fifteen","sixteen","seventeen","eighteen","nineteen"];
      const tens=["","","twenty","thirty","forty","fifty","sixty","seventy","eighty","ninety"];
      function chunk(n){ let s="",h=Math.floor(n/100),t=n%100;
        if(h) s+=ones[h]+" hundred";
        if(t){ if(s) s+=" "; if(t<10) s+=ones[t]; else if(t<20) s+=teens[t-10];
          else { s+=tens[Math.floor(t/10)]; if(t%10) s+="-"+ones[t%10]; } }
        return s||"zero";
      }
      if(num===0) return "zero";
      const units=[""," thousand"," million"," billion"], parts=[];
      for(let i=0; num>0 && i<units.length; i++){ const c=num%1000; if(c) parts.unshift(chunk(c)+units[i]); num=Math.floor(num/1000); }
      return parts.join(" ");
    }
    function normalizeNumbers(text){
      return text.replace(/\b\d{1,3}(?:,\d{3})+\b|\b\d{4,9}\b/g, m=>{
        const n=Number(m.replace(/,/g,"")); return Number.isFinite(n)?numberToWordsUS(n):m;
      });
    }
    async function ensureMini(){
      if (window.AiMini) return;
      await new Promise((ok,err)=>{
        const s=document.createElement("script");
        s.src="/mini-player.js?v=108";
        s.onload=ok; s.onerror=err;
        document.head.appendChild(s);
      });
    }
    function AIL_buildNarration(sel=SEL){
      const title = (document.querySelector("h1")?.innerText || "").trim();
      const dek   = (document.querySelector(".dek,.subtitle,h2")?.innerText || "").trim();
      const by    = (document.querySelector(".byline")?.textContent || "").replace(/^By\s*/i,"").trim();

      const root = document.querySelector(sel) || document.body;
      const clone = root.cloneNode(true);
      clone.querySelectorAll([
        "figure,figcaption,picture,video,iframe,svg,canvas",
        ".caption,.credit,.media,.gallery,.photo",
        "sup,sub,.citation,[role='doc-footnote'],.footnotes,.references",
        "aside,.related,.read-more,.recommended",
        "nav,header,footer,form,script,style"
      ].join(",")).forEach(n=>n.remove());

      const blocks=[];
      clone.querySelectorAll("p,li,blockquote,h2,h3").forEach(n=>{
        const s=(n.innerText||"").replace(/\s+/g," ").trim();
        if (s) blocks.push(s);
      });
      let body = blocks.join("\n\n");
      if (title && body.toLowerCase().startsWith(title.toLowerCase())) body = body.slice(title.length).trim();
      body = body.replace(/^\s*By\s+.+?(\.\s+|\n{1,}|  +)/i,"");

      const plain = [title, dek, by?`By ${by}`:"", body].filter(Boolean).join("\n\n");
      return { title, dek, by, plain };
    }

    let busy=false;
    async function play(){
      if (busy) return; busy=true;
      try{
        await ensureMini();

        const { title, dek, plain } = AIL_buildNarration();
        const pageTitle = title || "AI Listen";
        const subRaw    = dek || (document.querySelector(".byline")?.textContent?.trim()) || location.hostname;

        // open mini + bind timebar
        window.AiMini.open({ title: firstWords(pageTitle,5), subtitle: firstWords(subRaw,5) });
        setTimeout(()=>{ const t=document.querySelector("#ai-mini .ai-title"); if (t) t.title = pageTitle; },0);
        window.AIL_bindTimebar && window.AIL_bindTimebar();

        // ===== DEMO SHORT-CIRCUIT: use static MP3, skip backend =====
        if (window.AIL_DISABLE_TTS && window.AIL_AUDIO_URL) {
          const a = window.AiMini.audio?.()
                 || document.getElementById("ai-listen-audio")
                 || (()=>{ const el=document.createElement("audio"); el.id="ai-listen-audio"; document.body.appendChild(el); return el; })();
          try{ a.pause(); a.removeAttribute("src"); a.currentTime=0; }catch{}
          a.src = window.AIL_AUDIO_URL;
          a.preload = "auto";
          a.addEventListener("canplay", ()=>a.play().catch(()=>{}), { once:true });
          a.load();
          return; // <-- no network, cost $0
        }

        // ===== LIVE PATH (only when ?live=1) =====
        const spoken = normalizeNumbers(plain);
        const r = await fetch(BASE + "/api/tts", {
          method:"POST",
          headers:{ "content-type":"application/json", "x-tenant-key": TENANT },
          body: JSON.stringify({ text: spoken, voice_id: VOICE, preset: "news", bust: Date.now() })
        });
        const raw = await r.text();
        if (!r.ok) throw new Error(`TTS ${r.status}: ${raw}`);
        const j = JSON.parse(raw);
        let url = j.audioUrl || j.audio_url || j.url;
        if (url && !/^https?:\/\//i.test(url)) url = BASE + url;

        const a = window.AiMini.audio?.()
               || document.getElementById("ai-listen-audio")
               || (()=>{ const el=document.createElement("audio"); el.id="ai-listen-audio"; document.body.appendChild(el); return el; })();

        try{ a.pause(); a.removeAttribute("src"); a.currentTime=0; }catch{}
        a.src=url; a.preload="auto";
        a.addEventListener("canplay", ()=>a.play().catch(()=>{}), { once:true });
        a.load();
      }catch(e){
        console.error("[AIL hotfix] play failed", e);
        alert("Playback error (see console).");
      }finally{ busy=false; }
    }

    // one click binding; stop other handlers from double-firing
    document.addEventListener("click", (e)=>{
      const btn = e.target.closest("#ai-listen-btn");
      if (!btn) return;
      e.preventDefault();
      e.stopImmediatePropagation();
      play();
    });
  })();
  </script>

  <!-- ===== Time labels: wait for mini, then attach (elapsed / total) ===== -->
  <script>
  (function(){
    function fmt(t){ if(!isFinite(t)||t<0) return "0:00";
      const m=Math.floor(t/60), s=Math.floor(t%60);
      return m+":"+(s<10?"0"+s:s);
    }
    function bindWhenReady(){
      const mini = document.getElementById("ai-mini");
      if (!mini) return;
      const target = mini.querySelector(".ai-meter, .ai-progress");
      if (target) return bind(target);
      const mo = new MutationObserver(() => {
        const t = mini.querySelector(".ai-meter, .ai-progress");
        if (t){ mo.disconnect(); bind(t); }
      });
      mo.observe(mini, { childList:true, subtree:true });
    }
    function bind(target){
      let row = target.parentElement.querySelector(".ai-timebar");
      if (!row){
        row = document.createElement("div");
        row.className = "ai-timebar";
        row.innerHTML = `<span data-ai-elapsed>0:00</span><span data-ai-total>0:00</span>`;
        (target.parentElement || target).appendChild(row);
      }
      const el  = row.querySelector("[data-ai-elapsed]");
      const tot = row.querySelector("[data-ai-total]");
      const a = (window.AiMini && window.AiMini.audio && window.AiMini.audio())
             || document.getElementById("ai-listen-audio");
      if (!a) return;
      const updTot = ()=>{ if (tot) tot.textContent = fmt(a.duration); };
      const updCur = ()=>{ if (el)  el.textContent  = fmt(a.currentTime); };
      a.addEventListener("loadedmetadata", updTot);
      a.addEventListener("durationchange",  updTot);
      a.addEventListener("timeupdate",      updCur);
      a.addEventListener("ended",           updCur);
      updTot(); updCur();
    }
    window.AIL_bindTimebar = function(){
      if (document.getElementById("ai-mini")) bindWhenReady();
      else {
        const mo = new MutationObserver(()=>{
          if (document.getElementById("ai-mini")){ mo.disconnect(); bindWhenReady(); }
        });
        mo.observe(document.body, { childList:true, subtree:true });
      }
    };
  })();
  </script>

  <!-- ===== Don’t let the mini cover content (reserve bottom padding while open) ===== -->
  <script>
  (function(){
    function attach(mini){
      const root = document.documentElement;
      function setPad(){
        const h = mini.offsetHeight || 120;
        root.style.setProperty('--ai-mini-pad', (h + 16) + 'px');
        root.classList.add('ai-mini-open');
      }
      function clearPad(){ root.classList.remove('ai-mini-open'); }
      const mo = new MutationObserver(() => {
        if (mini.classList.contains('show')) setPad(); else clearPad();
      });
      mo.observe(mini, { attributes: true, attributeFilter: ['class','style'] });
      window.addEventListener('resize', () => { if (mini.classList.contains('show')) setPad(); });
      if (mini.classList.contains('show')) setPad();
    }
    function waitForMini(){
      const mini = document.getElementById('ai-mini');
      if (mini) return attach(mini);
      const obs = new MutationObserver(() => {
        const el = document.getElementById('ai-mini');
        if (el){ obs.disconnect(); attach(el); }
      });
      obs.observe(document.body, { childList: true, subtree: true });
    }
    if (document.readyState !== 'loading') waitForMini();
    else document.addEventListener('DOMContentLoaded', waitForMini);
  })();
  </script>

  <!-- ===== Conditional widget loader: only inject when NOT in demo ===== -->
  <script>
    (function(){
      if (window.AIL_DISABLE_TTS) return; // demo mode: skip widget (no backend)
      var s = document.createElement('script');
      s.async = true;
      s.src = "/tts-widget.v1.js?v=108";
      s.setAttribute('data-base',    'https://aivoicedemo.onrender.com');
      s.setAttribute('data-voice',   '21m00Tcm4TlvDq8ikWAM');
      s.setAttribute('data-tenant',  'demo123');
      s.setAttribute('data-selector','#demo-article');
      document.body.appendChild(s);
    })();
  </script>
</body>
</html>
